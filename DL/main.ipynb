{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DevOps\n",
    "\n",
    "I will be using the 128x128 CNN model for my DevOps project. To make it easier to quickly glance the important information I have made this section. \n",
    "\n",
    "### Model Training\n",
    "\n",
    "Since we are done finding the best model and will now be using it for a production use case, I think it is better to train the model on the whole dataset rather than a smaller portion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "\n",
    "# ML\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "# Miscellaneous\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ML\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Modelling\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 10:20:31.688491: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-01-19 10:20:31.688519: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-01-19 10:20:31.688527: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-01-19 10:20:31.688605: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-19 10:20:31.688655: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "ROOT = \"./Vegetable Images\"\n",
    "CLASSES = ['Broccoli','Capsicum','Bottle_Gourd','Radish','Tomato','Brinjal','Pumpkin','Carrot','Papaya','Cabbage','Bitter_Gourd','Cauliflower','Bean','Cucumber','Potato']\n",
    "tfClasses = tf.constant(CLASSES)\n",
    "TRAIN = tf.data.Dataset.list_files(f\"{ROOT}/train/*/*\")\n",
    "TEST = tf.data.Dataset.list_files(f\"{ROOT}/test/*/*\")\n",
    "VAL = tf.data.Dataset.list_files(f\"{ROOT}/validation/*/*\")\n",
    "dataCats = [\"train\",\"test\",\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classCounts = []\n",
    "for cat in dataCats:\n",
    "    class_distro = [len(tf.data.Dataset.list_files(f\"{ROOT}/{cat}/{i}/*\")) for i in CLASSES]\n",
    "    classCounts.append(class_distro)\n",
    "    \n",
    "train_distro = classCounts[0]\n",
    "\n",
    "targetSize = max(train_distro)\n",
    "additional_needed = [targetSize-i for i in train_distro]\n",
    "\n",
    "aug_train = []\n",
    "for i,v in enumerate(CLASSES):\n",
    "    path = f'{ROOT}/train/{v}'\n",
    "    imgNeeded = additional_needed[i]\n",
    "    images = os.listdir(path)[:imgNeeded]\n",
    "    aug_train.extend([path + \"/\" + i for i in images])\n",
    "train_data_aug = tf.data.Dataset.from_tensor_slices(aug_train)\n",
    "\n",
    "def createPreprocessor(imgSize):\n",
    "    def processing(path):\n",
    "        label = tf.strings.split(path , os.path.sep)\n",
    "        one_hot = label[-2] == tfClasses\n",
    "        label = tf.argmax(one_hot)\n",
    "        label = tf.one_hot(label, depth=len(CLASSES))\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, [imgSize, imgSize])\n",
    "        img = tf.image.rgb_to_grayscale(img)\n",
    "        img = img / 255.0\n",
    "        return img , label\n",
    "    return processing\n",
    "    \n",
    "def augmentation(image,label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.rot90(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    return image , label\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "  ds = ds.cache()\n",
    "  ds = ds.shuffle(buffer_size=1000)\n",
    "  ds = ds.batch(32)\n",
    "  ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "  return ds\n",
    "\n",
    "train_ori_large = TRAIN.map(createPreprocessor(128))\n",
    "train_aug_large = TRAIN.map(createPreprocessor(128)).map(augmentation)\n",
    "train_large_ds = train_ori_large.concatenate(train_aug_large)\n",
    "\n",
    "test_large_ds = TEST.map(createPreprocessor(128))\n",
    "val_large_ds = VAL.map(createPreprocessor(128))\n",
    "\n",
    "data = train_large_ds.concatenate(test_large_ds).concatenate(val_large_ds)\n",
    "data = configure_for_performance(data)\n",
    "\n",
    "train_ori_small = TRAIN.map(createPreprocessor(31))\n",
    "train_aug_small = TRAIN.map(createPreprocessor(31)).map(augmentation)\n",
    "train_small_ds = train_ori_small.concatenate(train_aug_small)\n",
    "\n",
    "test_small_ds = TEST.map(createPreprocessor(31))\n",
    "val_small_ds = VAL.map(createPreprocessor(31))\n",
    "\n",
    "data_small = train_small_ds.concatenate(test_small_ds).concatenate(val_small_ds)\n",
    "data_small = configure_for_performance(data_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_cnn_model = tf.keras.Sequential([\n",
    "    Conv2D(16, 3, activation='relu', input_shape=(31, 31, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(),\n",
    "    \n",
    "    Conv2D(32, 3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(),\n",
    "    \n",
    "    Conv2D(64, 3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5), \n",
    "    Dense(15, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_cnn_model_large = tf.keras.Sequential([\n",
    "    Conv2D(32, 3, activation='relu', input_shape=(128, 128, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(),\n",
    "    \n",
    "    Conv2D(64, 3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(),\n",
    "    \n",
    "    Conv2D(128, 3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(),\n",
    "    \n",
    "    Conv2D(256, 3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5), \n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5), \n",
    "    \n",
    "    Dense(15, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=1, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 10:25:19.314150: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 18s 20ms/step - loss: 3.1853 - accuracy: 0.2097 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 2.1016 - accuracy: 0.3494 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 1.8340 - accuracy: 0.4186 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 1.6516 - accuracy: 0.4746 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 1.5460 - accuracy: 0.5139 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 1.4566 - accuracy: 0.5486 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 1.3730 - accuracy: 0.5733 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 1.3249 - accuracy: 0.5942 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 1.2784 - accuracy: 0.6149 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 1.2528 - accuracy: 0.6245 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 1.2181 - accuracy: 0.6381 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 1.2088 - accuracy: 0.6426 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 1.2128 - accuracy: 0.6529 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 1.0330 - accuracy: 0.6963 - lr: 5.0000e-04\n",
      "Epoch 15/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 0.9999 - accuracy: 0.7012 - lr: 5.0000e-04\n",
      "Epoch 16/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 0.9867 - accuracy: 0.7067 - lr: 5.0000e-04\n",
      "Epoch 17/25\n",
      "752/752 [==============================] - 13s 18ms/step - loss: 0.9771 - accuracy: 0.7123 - lr: 5.0000e-04\n",
      "Epoch 18/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 0.9586 - accuracy: 0.7183 - lr: 5.0000e-04\n",
      "Epoch 19/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 0.9497 - accuracy: 0.7184 - lr: 5.0000e-04\n",
      "Epoch 20/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 0.9548 - accuracy: 0.7215 - lr: 5.0000e-04\n",
      "Epoch 21/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 0.8465 - accuracy: 0.7455 - lr: 2.5000e-04\n",
      "Epoch 22/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 0.8369 - accuracy: 0.7529 - lr: 2.5000e-04\n",
      "Epoch 23/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 0.8214 - accuracy: 0.7539 - lr: 2.5000e-04\n",
      "Epoch 24/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 0.8253 - accuracy: 0.7495 - lr: 2.5000e-04\n",
      "Epoch 25/25\n",
      "752/752 [==============================] - 13s 17ms/step - loss: 0.7754 - accuracy: 0.7694 - lr: 1.2500e-04\n",
      "INFO:tensorflow:Assets written to: ./cnn/small/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./cnn/small/assets\n"
     ]
    }
   ],
   "source": [
    "reg_cnn_model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "modelHist = reg_cnn_model.fit(\n",
    "      data_small, epochs=25, callbacks=[es,reduce_lr]\n",
    "    )\n",
    "\n",
    "reg_cnn_model.save(\"./cnn/small\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 37s 47ms/step - loss: 1.6099 - accuracy: 0.5079 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "752/752 [==============================] - 36s 48ms/step - loss: 0.7013 - accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "752/752 [==============================] - 36s 47ms/step - loss: 0.3771 - accuracy: 0.8877 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "752/752 [==============================] - 36s 47ms/step - loss: 0.2551 - accuracy: 0.9231 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "752/752 [==============================] - 35s 47ms/step - loss: 0.1957 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "752/752 [==============================] - 36s 48ms/step - loss: 0.1503 - accuracy: 0.9539 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "752/752 [==============================] - 36s 47ms/step - loss: 0.1055 - accuracy: 0.9670 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "752/752 [==============================] - 35s 47ms/step - loss: 0.1128 - accuracy: 0.9645 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "752/752 [==============================] - 37s 49ms/step - loss: 0.0568 - accuracy: 0.9849 - lr: 5.0000e-04\n",
      "Epoch 10/15\n",
      "752/752 [==============================] - 35s 46ms/step - loss: 0.0406 - accuracy: 0.9886 - lr: 5.0000e-04\n",
      "Epoch 11/15\n",
      "752/752 [==============================] - 36s 47ms/step - loss: 0.0393 - accuracy: 0.9889 - lr: 5.0000e-04\n",
      "Epoch 12/15\n",
      "752/752 [==============================] - 36s 47ms/step - loss: 0.0351 - accuracy: 0.9905 - lr: 5.0000e-04\n",
      "Epoch 13/15\n",
      "752/752 [==============================] - 36s 48ms/step - loss: 0.0312 - accuracy: 0.9900 - lr: 5.0000e-04\n",
      "Epoch 14/15\n",
      "752/752 [==============================] - 36s 47ms/step - loss: 0.0306 - accuracy: 0.9912 - lr: 5.0000e-04\n",
      "Epoch 15/15\n",
      "752/752 [==============================] - 36s 48ms/step - loss: 0.0304 - accuracy: 0.9908 - lr: 5.0000e-04\n",
      "INFO:tensorflow:Assets written to: ./cnn/large/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./cnn/large/assets\n"
     ]
    }
   ],
   "source": [
    "reg_cnn_model_large.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "modelHist2 = reg_cnn_model_large.fit(\n",
    "      data, epochs=15, callbacks=[es,reduce_lr]\n",
    "    )\n",
    "\n",
    "reg_cnn_model_large.save(\"./cnn/large\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Useful Information about our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 29, 29, 16)        160       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 29, 29, 16)        64        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 16)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 12, 12, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 4, 4, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 2, 2, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 15)                975       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41167 (160.81 KB)\n",
      "Trainable params: 40943 (159.93 KB)\n",
      "Non-trainable params: 224 (896.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reg_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           (None, 126, 126, 32)      320       \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 126, 126, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 63, 63, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 61, 61, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 28, 28, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 14, 14, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 12, 12, 256)       1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 6, 6, 256)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               2359552   \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 15)                1935      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2785679 (10.63 MB)\n",
      "Trainable params: 2783951 (10.62 MB)\n",
      "Non-trainable params: 1728 (6.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reg_cnn_model_large.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 2s 13ms/step - loss: 0.3646 - accuracy: 0.9000\n",
      "94/94 [==============================] - 2s 20ms/step - loss: 0.1092 - accuracy: 0.9597\n",
      "Prediction time for final_31: 1.6732401847839355 seconds\n",
      "Prediction time for final_128: 2.2491331100463867 seconds\n"
     ]
    }
   ],
   "source": [
    "# Measure prediction time for final_31\n",
    "start_time = time.time()\n",
    "prediction_31 = reg_cnn_model.evaluate(configure_for_performance(test_small_ds))\n",
    "end_time = time.time()\n",
    "time_taken_31 = end_time - start_time\n",
    "\n",
    "# Measure prediction time for final_128\n",
    "start_time = time.time()\n",
    "prediction_128 = reg_cnn_model_large.evaluate(configure_for_performance(test_large_ds))\n",
    "end_time = time.time()\n",
    "time_taken_128 = end_time - start_time\n",
    "\n",
    "# Print the prediction times\n",
    "print(f\"Prediction time for final_31: {time_taken_31} seconds\")\n",
    "print(f\"Prediction time for final_128: {time_taken_128} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the larger model takes abit longer but is also abit more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Serving\n",
    "\n",
    "Now that we are done training and saving our models in the TF SavedModel format, we can run a series of commands as seen below to create our Tensorflow  Serving Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
